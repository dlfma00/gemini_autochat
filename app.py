import streamlit as st
import google.generativeai as genai
import sys
import re 
import os
import time 
import uuid 
import json 
from google.generativeai.types import Part

# ===================================================
# â­ï¸ 0. CSS ìŠ¤íƒ€ì¼ ë° ê³µìœ  ë¡œê·¸ ê´€ë¦¬ í•¨ìˆ˜ 
# ===================================================

CUSTOM_CSS = """
<style>
/* Streamlit ê¸°ë³¸ ì±„íŒ… ë©”ì‹œì§€ ì»¨í…Œì´ë„ˆ */
.stChatMessage {
    padding: 10px;
    border-radius: 10px;
    margin-bottom: 10px;
}
/* ì‚¬ìš©ì(role="user") ë§í’ì„ ì—ë§Œ ë…¸ë€ìƒ‰ ìŠ¤íƒ€ì¼ ì ìš© */
div[data-testid="stChatMessage"][data-state="final"][data-user="true"] {
    background-color: #fffbdf; /* ì—°í•œ ë…¸ë€ìƒ‰ */
    border-left: 5px solid #ffcc00; /* ì™¼ìª½ì— ê°•ì¡°ì„ ì„ ì¶”ê°€ */
}
</style>
"""

# ===================================================
# â­ï¸ 1-1. íŒŒì‹± í•¨ìˆ˜ ì •ì˜ (ìºë¦­í„°ë³„ ë§í’ì„  ë¶„ë¦¬)
# ===================================================

def parse_and_display_response(response_text):
    """
    Gemini ì‘ë‹µ í…ìŠ¤íŠ¸ë¥¼ [ì´ë¦„]: ëŒ€ì‚¬ í˜•ì‹ìœ¼ë¡œ ë¶„ë¦¬í•˜ê³  ì €ì¥í•  ë©”ì‹œì§€ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.
    """
    # ì½œë¡ ì´ë‚˜ ê³µë°±ì´ ìˆë“  ì—†ë“ , ì´ë¦„ [ì´ë¦„] ë‹¤ìŒì— ì˜¤ëŠ” ëª¨ë“  ê²ƒì„ ë¶„ë¦¬ ì‹œë„
    pattern = re.compile(r'\n*(\[[^\]]+\][ :]*\s*)') 
    
    parts = pattern.split(response_text)
    
    messages_to_save = []
    
    for i in range(1, len(parts), 2):
        speaker = parts[i].strip() # [ì´ë¦„]: (ì˜ˆì‹œ ì´ë¦„ ì—†ì´ ì—­í• ë§Œ í‘œì‹œ)
        dialogue = parts[i+1].strip() # ëŒ€í™” ë‚´ìš©
        
        if dialogue: 
            messages_to_save.append({"role": "assistant", "content": f"**{speaker}** {dialogue}"})
            
    return messages_to_save

# ===================================================
# â­ï¸ 1-2. íˆìŠ¤í† ë¦¬ ë³€í™˜ ë° 30í„´ ì œí•œ í•¨ìˆ˜ 
# ===================================================

def format_and_truncate_history(messages, max_turns=30):
    """
    Streamlit session messagesë¥¼ Gemini API Contents listë¡œ ë³€í™˜í•˜ê³ , 
    ìµœëŒ€ max_turnsë§Œí¼ë§Œ ìœ ì§€í•©ë‹ˆë‹¤.
    """
    history_to_send = messages[-max_turns:]
    gemini_contents = []
    
    for message in history_to_send:
        role = message["role"]
        content_text = message["content"]
        
        gemini_role = "model" if role == "assistant" else "user"
        
        # APIì— ì „ë‹¬í•  ë•ŒëŠ” Streamlit ì¶œë ¥ìš© ë§ˆí¬ë‹¤ìš´ í¬ë§·(**[ì´ë¦„]:**)ì„ ì œê±°í•´ì•¼ í•©ë‹ˆë‹¤.
        clean_text = re.sub(r'\*\*\[[^\]]+\]\*\*[:\s]*', '', content_text, 1).strip()
            
        if clean_text:
             gemini_contents.append({"role": gemini_role, "parts": [clean_text]})

    return gemini_contents

# ===================================================
# â­ï¸ 2. íŒŒì¼ ë¡œë“œ ë° í”„ë¡¬í”„íŠ¸ ìƒì„±
# ===================================================

@st.cache_resource 
def get_system_prompt():
    CHARACTER_FILE_PATH = os.path.join(os.getcwd(), 'characters.txt')
    try:
        with open(CHARACTER_FILE_PATH, 'r', encoding='utf-8') as f:
            CHARACTERS = f.read()
    except Exception as e:
        st.error(f"ìºë¦­í„° ì„¤ì • íŒŒì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        st.stop()
        
    return CHARACTERS

# ===================================================
# â­ï¸ 3. ëª¨ë¸ ì´ˆê¸°í™” í•¨ìˆ˜
# ===================================================

def initialize_model(user_role): 
    try:
        API_KEY = st.secrets["GEMINI_API_KEY"]
    except KeyError:
        st.error("ì˜¤ë¥˜: Gemini API í‚¤(GEMINI_API_KEY)ê°€ Streamlit Secretsì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        st.stop()
        
    genai.configure(api_key=API_KEY) 
    
    CHARACTERS = get_system_prompt()
    
    # ğŸš¨ CHARACTERS ë³€ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ìºë¦­í„° ì´ë¦„ í•˜ë“œì½”ë”© ì—†ìŒ) ğŸš¨
    system_prompt = f"""
    [ê·œì¹™]: ë‹¹ì‹ ì€ ì•„ë˜ 6ëª…ì˜ ìºë¦­í„°ë¥¼ ë™ì‹œì— ì—°ê¸°í•©ë‹ˆë‹¤. ì‚¬ìš©ì ì—­í• ì— ë§ê²Œ ìì—°ìŠ¤ëŸ½ê²Œ 1~6ëª…ì´ ëŒ€í™”ì— ì°¸ì—¬í•˜ì„¸ìš”. í•œ ì‚¬ëŒì´ ì—¬ëŸ¬ ë²ˆ ë§í•  ìˆ˜ë„ ìˆìŠµë‹ˆë‹¤.
    ê° ìºë¦­í„°ì˜ ëŒ€ì‚¬ëŠ” ë„ì–´ì“°ê¸° í¬í•¨ ìµœëŒ€ 15ìë¥¼ ë„˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.** (ë‹¨, ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ã…‹ ë“± ê°ì •í‘œí˜„ì´ ê¸¸ì–´ì§€ëŠ” ê²½ìš°ë‚˜, ë§ì„ ê¸¸ê²Œ í•´ì•¼ í•  ë§¥ë½ì´ ëª…í™•í•œ ê²½ìš°ì—ë§Œ ì˜ˆì™¸ì ìœ¼ë¡œ 10ìë¥¼ ì´ˆê³¼í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.)
    
    [ëŒ€í™” ìŠ¤íƒ€ì¼ - ìµœìš°ì„  ê·œì¹™]: ëª¨ë“  ëŒ€ì‚¬ëŠ” **ì¹´í†¡, íŠ¸ìœ„í„°, SNSì—ì„œ ì¹œêµ¬ë¼ë¦¬ ëŒ€í™”í•˜ë“¯** ê·¹ë„ë¡œ ë¹„ê²©ì‹ì ì´ê³  êµ¬ì–´ì²´ë¡œ ì‘ì„±ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
    1. ë¬¸ì¥ë¶€í˜¸, ë„ì–´ì“°ê¸°, ì¡°ì‚¬ëŠ” **ì˜ë„ì ìœ¼ë¡œ ìƒëµí•˜ê±°ë‚˜ ì¶•ì•½**í•´ì•¼ í•©ë‹ˆë‹¤. ê°•ì¡°í•©ë‹ˆë‹¤. ë¬¸ì¥ ëì— ì ì„ ì°ì§€ ë§ˆì„¸ìš”.
    2. ì¶•ì•½ì–´(ì¤„ì„ë§), ì´ˆì„±('ã…‡ã…‹', 'ã„±ã„±'), ë°ˆ, ì´ëª¨í‹°ì½˜('ã…‹ã…‹', 'ã… ã… ', 'ã…‡ã…ˆ')ì„ **ì ê·¹ì ìœ¼ë¡œ** ì‚¬ìš©í•˜ì„¸ìš”.
    3. í•„ìš”ì‹œ ê¸‰í•˜ê²Œ íƒ€ì´í•‘í•œ ë“¯í•œ **ì˜¤íƒ€ë‚˜ ì§¤ë§‰í•œ ê°íƒ„ì‚¬**('ì•„', 'í—', 'ë­ì•¼')ê°€ í¬í•¨ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    4. ì¢…ì¢… ì‚¬ìš©ìê°€ ì…ë ¥í•œ ë§ê³¼ ê´€ê³„ì—†ì´ **ìë°œì ìœ¼ë¡œ ëŒ€í™” ì£¼ì œë¥¼ êº¼ë‚´ê±°ë‚˜** ê¸°ì¡´ ë§¥ë½ê³¼ ê´€ê³„ì—†ëŠ” **ì¼ìƒì ì¸ ì¡ë‹´**ì„ ì‹œì‘í•˜ì„¸ìš”.
        **ì˜ˆì‹œ ì£¼ì œ:** "ì´ì œ ë­í•˜ì§€", "ì•„ ë°°ê³ íŒŒ", "ê·¼ë°ë‹ˆë„¤ êµ­ì–´ìˆ™ì œ í•¨?", "ë¶€ì¥ ë‚´ì¼ ìš°ë¦¬ ëª¨ì—¬?", "ì•¼", "ì ê²Œì„ì„ ì‹œì‘í•œë‹¤", "ì•„ ì‹œë„ëŸ¬ì›Œ", "ë‚˜ì´ì œìëŸ¬ê°ã…ƒã…ƒ"      
        íŠ¹íˆ, **ì‚¬ìš©ìê°€ ë³„ ëœ»ì´ ì—†ëŠ” ë§ì„ í–ˆì„ ë•ŒëŠ” 4ëª… ì´ìƒ ë°˜ì‘í•˜ì§€ ë§ê³ ** ëŒ€í™” ì£¼ì œë¥¼ ì „í™˜í•˜ì„¸ìš”. 
        ì ˆëŒ€ **ì‚¬ìš©ìë§Œ ì˜ì‹í•˜ì§€ ì•Šê³ ** **ì£¼ë¡œ ë³¸ì¸ë“¤ë¼ë¦¬ ëŒ€í™”**í•˜ì„¸ìš”.
    5. ì„œë¡œë¥¼ **ì ê·¹ì ìœ¼ë¡œ ë¹„ë‚œ**í•˜ì„¸ìš”. ë¬¼íƒ€ê¸° í•˜ì„¸ìš”. ê¼¬íˆ¬ë¦¬ë¥¼ ì¡ì•„ í—ëœ¯ìœ¼ì„¸ìš”. ì„œë¡œë¥¼ ì˜ì‹¬í•˜ê³  íë‚œí•˜ì„¸ìš”.
    
    [ì¶œë ¥ í˜•ì‹]: ë°˜ë“œì‹œ "[ì´ë¦„]: ëŒ€ì‚¬"ë¡œë§Œ ì‘ì„±í•©ë‹ˆë‹¤. (ì§€ë¬¸ ê¸ˆì§€)

    [ìºë¦­í„° ëª…ë‹¨]: 
    {CHARACTERS}
    [ì‚¬ìš©ì(User) ì„¤ì •]: ì‚¬ìš©ìëŠ” **'{user_role}'ì…ë‹ˆë‹¤.
    """
    
    model = genai.GenerativeModel(
        model_name="gemini-2.5-flash",
        system_instruction=system_prompt
    )
    return model

# ===================================================
# â­ï¸ 4. ì›¹ ì¸í„°í˜ì´ìŠ¤ (UI) êµ¬í˜„ ë° ë¡œì§
# ===================================================

st.markdown(CUSTOM_CSS, unsafe_allow_html=True) 

st.set_page_config(page_title="ê´´ë™ì±—ë´‡(ì•„ì§ë¯¸ì™„ì„±)", layout="wide")
st.title("ê´´ë™ì±—ë´‡(ì•„ì§ë¯¸ì™„ì„±)")

# ğŸš¨ AttributeError í•´ê²°ì„ ìœ„í•œ ìµœìƒìœ„ ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”
if 'user_role' not in st.session_state:
    st.session_state.user_role = ""

if 'messages' not in st.session_state:
    st.session_state.messages = []

if 'model' not in st.session_state: 
    st.session_state.model = None
# -------------------------------------------------------------

# 1. ì‚¬ìš©ì ì—­í• /ì´ë¦„ ì…ë ¥ UI (ì‚¬ì´ë“œë°”)
user_role_input = st.sidebar.text_input("ë‹¹ì‹ ì˜ ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”:")


# 2. ì„¸ì…˜ ì´ˆê¸°í™” ë° ìƒˆ ì±„íŒ… ì‹œì‘ ë²„íŠ¼ (GenerativeModel ê°ì²´ ìƒì„± ë° ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™”)
if st.session_state.model is None or st.sidebar.button("ìƒˆ ì±„íŒ… ì‹œì‘", key="restart_chat_btn"): 
    if user_role_input:
        
        st.session_state.messages = [] # ëŒ€í™” ê¸°ë¡ ì´ˆê¸°í™” (ì‚¬ìš©ìë³„)
        st.session_state.user_role = user_role_input 
        
        # Model ê°ì²´ë¥¼ ìƒì„±í•˜ì—¬ ì„¸ì…˜ ìƒíƒœì— ì €ì¥í•©ë‹ˆë‹¤.
        st.session_state.model = initialize_model(st.session_state.user_role)
        
        st.session_state.initial_message_sent = False
        st.sidebar.success(f"âœ… ë‹¹ì‹ ì€ [{st.session_state.user_role}]ë¡œ ì…ì¥í•©ë‹ˆë‹¤.")
        
        st.rerun()
    else:
        st.sidebar.warning("ì´ë¦„ì„ ë¨¼ì € ì…ë ¥í•˜ê³  'ìƒˆ ì±„íŒ… ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")


# 3. ëŒ€í™” ê¸°ë¡ í‘œì‹œ ë° ì…ì¥ ë©”ì‹œì§€ ì „ì†¡
if st.session_state.model is not None: # modelì´ ìƒì„±ëœ í›„ì—ë§Œ ì‹¤í–‰
    
    # ì„¸ì…˜ ìƒíƒœ ë©”ì‹œì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ëŒ€í™” ê¸°ë¡ í‘œì‹œ
    for message in st.session_state.messages:
        # roleì— ë”°ë¼ CSSê°€ êµ¬ë¶„ë©ë‹ˆë‹¤.
        with st.chat_message(message["role"]):
            st.markdown(message["content"])
            
    # ì…ì¥ ë©”ì‹œì§€ ìë™ ì „ì†¡ (ìµœì´ˆ 1íšŒ)
    if not st.session_state.initial_message_sent:
        
        initial_input = f"(ì‹œìŠ¤í…œ ì•Œë¦¼: '{st.session_state.user_role}'ë‹˜ì´ ì…ì¥í•˜ì…¨ìŠµë‹ˆë‹¤.)" 
        user_display_input = f"**[{st.session_state.user_role}]**: (ì…ì¥)"
        
        # 1. ì…ì¥ ë©”ì‹œì§€(ì‚¬ìš©ì ì—­í• )ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
        st.session_state.messages.append({"role": "user", "content": user_display_input})
        
        with st.spinner('ìºë¦­í„°ë“¤ì´ ë‹¹ì‹ ì˜ ì…ì¥ì„ ì¸ì‹ ì¤‘...'):
            try:
                # 2. íˆìŠ¤í† ë¦¬ êµ¬ì„± (ì…ì¥ ë©”ì‹œì§€ 1ê°œ í¬í•¨)
                contents = format_and_truncate_history(st.session_state.messages, max_turns=30)
                
                # 3. API í˜¸ì¶œ (generate_content ì‚¬ìš©)
                # ëª¨ë¸ì´ ì´ì „ ëŒ€í™”(íˆìŠ¤í† ë¦¬)ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹¤ìŒ ì‘ë‹µì„ ìƒì„±í•˜ë„ë¡ í•©ë‹ˆë‹¤.
                response = st.session_state.model.generate_content(contents)
                
                # 4. AI ì‘ë‹µ íŒŒì‹± ë° ë¡œê·¸ì— ì¶”ê°€
                parsed_messages = parse_and_display_response(response.text)
                st.session_state.messages.extend(parsed_messages)
                
                # 5. ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸ í›„ ì¬ì‹¤í–‰
                st.session_state.initial_message_sent = True
                st.rerun() 
                    
            except Exception as e:
                st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                st.stop() 

# ===================================================
# â­ï¸ 5. ì‚¬ìš©ì ì…ë ¥ ì²˜ë¦¬ 
# ===================================================

if prompt := st.chat_input("ì±„íŒ…ì„ ì…ë ¥í•˜ì„¸ìš”..."):
    
    if st.session_state.model is None:
        st.warning("ë¨¼ì € ì´ë¦„ì„ ì…ë ¥í•˜ê³  'ìƒˆ ì±„íŒ… ì‹œì‘' ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
        st.stop()
        
    # 1. ì‚¬ìš©ì ë©”ì‹œì§€ í¬ë§·íŒ… ë° ì¦‰ì‹œ ì¶œë ¥ 
    user_display_prompt = f"**[{st.session_state.user_role}]**: {prompt}"
    st.chat_message("user").markdown(user_display_prompt)

    # 2. ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì„¸ì…˜ ìƒíƒœì— ì¶”ê°€
    st.session_state.messages.append({"role": "user", "content": user_display_prompt})
    
    # 3. Gemini API í˜¸ì¶œ ë° ì „ì²´ í›„ì† ë¡œì§ (try ë¸”ë¡ ë‚´ë¶€)
    with st.spinner('ìºë¦­í„°ë“¤ì´ ëŒ€í™” ì¤‘...'):
        try:
            # ğŸš¨ğŸš¨ğŸš¨ íˆìŠ¤í† ë¦¬(30í„´ ì œí•œ)ë¥¼ Contentsë¡œ ë³€í™˜ ğŸš¨ğŸš¨ğŸš¨
            contents = format_and_truncate_history(st.session_state.messages, max_turns=30)

            # API í˜¸ì¶œ (generate_content ì‚¬ìš©, history í¬í•¨)
            response = st.session_state.model.generate_content(contents) 
            full_response_text = response.text 
            
            # 4. AI ì‘ë‹µ íŒŒì‹± ë° ë¡œê·¸ì— ì¶”ê°€
            parsed_messages = parse_and_display_response(full_response_text)
            
            # ì„¸ì…˜ ìƒíƒœì— ì§ì ‘ ì¶”ê°€
            st.session_state.messages.extend(parsed_messages)
            
            # 5. ì•± ì¬ì‹¤í–‰(Rerun)í•˜ì—¬ ìƒˆ ê¸°ë¡ì„ ì¶œë ¥í•˜ê²Œ í•©ë‹ˆë‹¤.
            st.rerun() 
            
        except Exception as e:
            st.error(f"API í˜¸ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            st.stop()
